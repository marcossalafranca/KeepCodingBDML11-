{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa de preprocesado de texto"
      ],
      "metadata": {
        "id": "2tIQxaryU4Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lnQC76Q6qM2",
        "outputId": "150d5164-f3bb-4e0a-a5fe-56f9ae8ea494"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "x8K1WHT5UyxL"
      },
      "outputs": [],
      "source": [
        "# Librerias\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from num2words import num2words\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montamos GDrive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVFN_YjxWEV8",
        "outputId": "7db80a8f-facb-4b34-c38c-75afdc5b8e11"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset\n",
        "df = pd.read_csv('drive/MyDrive/NLP/sampled_data_file.csv')"
      ],
      "metadata": {
        "id": "72AcsXNCU7P9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Descargar la lista de palabras vacías\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "stopwords = set(stopwords) - set(['not', 'no', 'nor', 'but'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EeJCXarWqC3",
        "outputId": "96f549b5-2898-4888-ac01-9c8884cdb40e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga el recurso punkt\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPbZdeofWrvj",
        "outputId": "c172d5de-03cd-4eb6-8f99-b06beb096a8e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar la base de datos de WordNet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "# Crear el lematizador\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU6CK_9BWt9g",
        "outputId": "511f5b10-aee7-4db3-9d74-ebd63a286dde"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la función para preprocesar el texto\n",
        "\n",
        "def preprocess(text):\n",
        "    # Obtener todo el texto en minúsculas:\n",
        "    text = text.lower()\n",
        "    # Eliminar puntuación:\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # tokenizar el texto:\n",
        "    text = nltk.word_tokenize(text)\n",
        "    # Inicializar lematizador:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # Obtener lista de palabras vacías (stopwords):\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "    # Inicializar lista para almacenar texto limpio:\n",
        "    clean_text = []\n",
        "    for word in text:\n",
        "        #Eliminar palabras vacías:\n",
        "        if word not in stopwords:\n",
        "            #Lematizar el texto:\n",
        "            token = lemmatizer.lemmatize(word)\n",
        "            # Convertir dígitos a palabras:\n",
        "            if token.isdigit():\n",
        "                token = num2words(token, lang='en')\n",
        "            clean_text.append(token)\n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "Z7hFGzL2WuEd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviewText'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "O5BnLO21Wygy",
        "outputId": "aa638b70-68ae-4c99-e548-36104b57d4ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The helicopter stopped working after 10 minutes, the tail motor burn out making the helicopter useless, It took 4 weeks to get here, was shipped in a Styrofoam box that looked like it was taken out of the garage wrapped with shipping tape, the helicopter and other parts raddled around inside of the box did not even fit inside the cut outs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = df['reviewText'][0]\n",
        "preprocess(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukuPDTJuW0Xd",
        "outputId": "2180b5ee-5fe8-4bfa-9486-0e45862426cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['helicopter',\n",
              " 'stopped',\n",
              " 'working',\n",
              " 'ten',\n",
              " 'minute',\n",
              " 'tail',\n",
              " 'motor',\n",
              " 'burn',\n",
              " 'making',\n",
              " 'helicopter',\n",
              " 'useless',\n",
              " 'took',\n",
              " 'four',\n",
              " 'week',\n",
              " 'get',\n",
              " 'shipped',\n",
              " 'styrofoam',\n",
              " 'box',\n",
              " 'looked',\n",
              " 'like',\n",
              " 'taken',\n",
              " 'garage',\n",
              " 'wrapped',\n",
              " 'shipping',\n",
              " 'tape',\n",
              " 'helicopter',\n",
              " 'part',\n",
              " 'raddled',\n",
              " 'around',\n",
              " 'inside',\n",
              " 'box',\n",
              " 'even',\n",
              " 'fit',\n",
              " 'inside',\n",
              " 'cut',\n",
              " 'out']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar el preproceso en los datos\n",
        "df['reviewText'] = df['reviewText'].apply(preprocess)"
      ],
      "metadata": {
        "id": "IYulXCzmW5HB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear nuevo csv con el texto preprocesado\n",
        "df_preprocessed = df[['overall', 'reviewText']]\n",
        "df_preprocessed.to_csv('drive/MyDrive/NLP/df_preprocessed.csv', index=False)"
      ],
      "metadata": {
        "id": "HfDiPP3yW7y5"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}